<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Vision | Ganeshan Malhotra</title>
    <link>https://ganeshan007.github.io/tag/computer-vision/</link>
      <atom:link href="https://ganeshan007.github.io/tag/computer-vision/index.xml" rel="self" type="application/rss+xml" />
    <description>Computer Vision</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 27 May 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ganeshan007.github.io/img/MyPic.jpg</url>
      <title>Computer Vision</title>
      <link>https://ganeshan007.github.io/tag/computer-vision/</link>
    </image>
    
    <item>
      <title>Driver Drowsiness Setection using Eye State Information</title>
      <link>https://ganeshan007.github.io/project/internal-project/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate>
      <guid>https://ganeshan007.github.io/project/internal-project/</guid>
      <description>&lt;p&gt;The project aims at predicting Driver Drowsiness using the eye state of the driver using state of the art deep learning technologies. The face detector used was dlib&amp;rsquo;s pretrained face detector which has 68 facial landmark features. The model included taking the livestream data and extracting features using the Eye Aspect Ratio(EAR). The data was then preprocessed into features. To use the temporal information, we made use of Bidirectional-LSTMs in our model architecture. The output was then classified into 3 states&amp;ndash; Alert, Semi-sleepy or Sleepy.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multi-Modal Sentiment Analysis</title>
      <link>https://ganeshan007.github.io/project/internal-project-copy-2/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate>
      <guid>https://ganeshan007.github.io/project/internal-project-copy-2/</guid>
      <description>&lt;p&gt;Classified memes as hateful or not using image and text associated with it. Used Glove embeddings for text and ResNet50 based model for images.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Video Classification Using Keras</title>
      <link>https://ganeshan007.github.io/project/internal-project-copy/</link>
      <pubDate>Mon, 27 May 2019 00:00:00 +0000</pubDate>
      <guid>https://ganeshan007.github.io/project/internal-project-copy/</guid>
      <description>&lt;p&gt;The project classified videos based on the activity shown in the video. The dataset used was the Youtube action dataset. The consecutive frames of the video were captured as images using OpenCv. Then Resnet50 was used as the base model with weights trained on the imagenet dataset. The head of the model included AveragePool , dense and softmax layers to classify the video correctly. Then for predicion rolling average was used to make use of the temporal information&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
